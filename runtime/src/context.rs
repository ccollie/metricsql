use std::sync::{Arc};
use chrono::{Duration};

use crate::active_queries::ActiveQueries;
use crate::cache::rollup_result_cache::RollupResultCache;
use crate::{ActiveQueryEntry, MetricDataProvider, NullMetricDataProvider};
use crate::parser_cache::{ParseCache, ParseCacheValue};
use crate::query_stats::query_stats::QueryStatsTracker;
use crate::runtime_error::{RuntimeError, RuntimeResult};
use crate::search::{Deadline, QueryResults, SearchQuery};

const DEFAULT_MAX_QUERY_LEN: usize = 16 * 1024;
const DEFAULT_MAX_UNIQUE_TIMESERIES: usize = 1000;
const DEFAULT_LATENCY_OFFSET: usize = 30 * 1000;

// todo; should this be a trait ?
pub struct Context {
    pub config: SessionConfig,
    pub parse_cache: ParseCache,
    pub rollup_result_cache: RollupResultCache,
    pub(crate) active_queries: ActiveQueries,
    pub query_stats: QueryStatsTracker,
    pub metric_data_provider: Arc<dyn MetricDataProvider + Send + Sync>, // mutex
}

impl Context {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn process_search_query(&self, sq: &SearchQuery, deadline: &Deadline) -> RuntimeResult<QueryResults> {
        self.metric_data_provider.search(sq, deadline)
    }

    pub fn parse_promql(&self, q: &str) -> RuntimeResult<Arc<ParseCacheValue>> {
        let cached = self.parse_cache.parse(q);
        if let Some(err) = &cached.err {
            return Err(RuntimeError::ParseError(err.clone()))
        }
        return Ok(cached)
    }

    pub fn get_active_queries(&self) -> Vec<ActiveQueryEntry> {
        self.active_queries.get_all()
    }
}

impl Default for Context {
    fn default() -> Self {
        Self {
            config: Default::default(),
            parse_cache: Default::default(),
            rollup_result_cache: Default::default(),
            active_queries: ActiveQueries::new(),
            query_stats: Default::default(),
            metric_data_provider: Arc::new(NullMetricDataProvider {}),
        }
    }
}


pub struct SessionState {
    pub config: SessionConfig,
}

impl Default for SessionState {
    fn default() -> Self {
        Self {
            config: SessionConfig::default(),
        }
    }
}

/// Global configuration options for request context
#[derive(Clone, Debug)]
pub struct SessionConfig {
    /// should we log query stats
    pub stats_enabled: bool,

    /// Whether to disable response caching. This may be useful during data backfilling"
    pub disable_cache: bool,

    /// The maximum search query length in bytes
    pub max_query_len: usize,

    /// The time when data points become visible in query results after the collection.
    /// Too small value can result in incomplete last points for query results
    pub latency_offset: Duration,

    /// The maximum amount of memory a single query may consume. Queries requiring more memory are
    /// rejected. The total memory limit for concurrently executed queries can be estimated as
    /// -search.maxMemoryPerQuery multiplied by -search.maxConcurrentQueries
    pub max_memory_per_query: usize,

    /// Set this flag to true if the database doesn't contain Prometheus stale markers, so there is
    /// no need in spending additional CPU time on its handling. Staleness markers may exist only in
    /// data obtained from Prometheus scrape targets
    pub no_stale_markers: bool,

    /// The maximum number of points per series, which can be generated by subquery.
    /// See https://valyala.medium.com/prometheus-subqueries-in-victoriametrics-9b1492b720b3
    pub max_points_subquery_per_timeseries: i64,

    /// The maximum interval for staleness calculations. By default it is automatically calculated from
    /// the median interval between samples. This could be useful for tuning Prometheus data model
    /// closer to Influx-style data model.
    /// See https://prometheus.io/docs/prometheus/latest/querying/basics/#staleness for details.
    /// See also 'set_lookback_to_step' flag
    pub max_staleness_interval: Duration,

    /// The minimum interval for staleness calculations. This could be useful for removing gaps on
    /// graphs generated from time series with irregular intervals between samples.
    pub min_staleness_interval: Duration,

    /// The maximum number of unique time series to be returned from instant or range queries
    /// This option allows limiting memory usage
    pub max_unique_timeseries: usize,

    /// Synonym to -search.lookback-delta from Prometheus.
    /// The value is dynamically detected from interval between time series datapoints if not set.
    /// It can be overridden on per-query basis via max_lookback arg.
    /// See also 'max_staleness_interval' flag, which has the same meaning due to historical reasons"
    pub max_lookback: Duration,

    /// Whether to fix lookback interval to `step` query arg value.
    /// If set to true, the query model becomes closer to InfluxDB data model. If set to true,
    /// then `max_lookback` and `max_staleness_interval` are ignored. Defaylts to `false`
    pub set_lookback_to_step: bool,

    /// The maximum step when the range query handler adjusts points with timestamps closer than
    /// `latency_offset` to the current time. The adjustment is needed because such points may contain
    /// incomplete data
    pub max_step_for_points_adjustment: Duration,

    /// The maximum duration for query execution (default 30 secs)
    pub max_query_duration: Duration
}

impl SessionConfig {
    /// Create an execution config with default setting
    pub fn new() -> Self {
        Default::default()
    }

    pub fn with_cache(mut self, caching: bool) -> Self {
        self.disable_cache = !caching;
        self
    }

    pub fn with_stale_markers(mut self, has_markers: bool) -> Self {
        self.no_stale_markers = !has_markers;
        self
    }

    pub fn with_stats_enabled(mut self, stats_enabled: bool) -> Self {
        self.stats_enabled = stats_enabled;
        self
    }
}

impl Default for SessionConfig {
    fn default() -> Self {
        SessionConfig {
            stats_enabled: false,
            disable_cache: false,
            max_query_len: DEFAULT_MAX_QUERY_LEN,
            latency_offset: Duration::milliseconds(DEFAULT_LATENCY_OFFSET as i64),
            max_memory_per_query: 0,
            no_stale_markers: true,
            max_points_subquery_per_timeseries: 0,
            max_staleness_interval: Duration::milliseconds(0),
            min_staleness_interval: Duration::milliseconds(0),
            max_unique_timeseries: DEFAULT_MAX_UNIQUE_TIMESERIES,
            max_lookback: Duration::milliseconds(0),
            set_lookback_to_step: false,
            max_step_for_points_adjustment: Duration::minutes(1),
            max_query_duration: Duration::seconds(30)
        }
    }
}
